{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aruco detectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pointgrey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PySpin\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog\n",
    "import threading\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class CameraApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Camera Acquisition App\")\n",
    "\n",
    "        # Variables to store camera settings\n",
    "        self.fps = tk.IntVar(value=30)\n",
    "        self.exposure = tk.IntVar(value=5000)\n",
    "        self.output_filename = tk.StringVar(value='output')\n",
    "\n",
    "        # Create GUI elements\n",
    "        self.create_widgets()\n",
    "\n",
    "        # ArUco detector\n",
    "        self.detector = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)\n",
    "\n",
    "        # VideoWriter and CSV file variables\n",
    "        self.out = None\n",
    "        self.csv_file = None\n",
    "        self.stop_acquisition = threading.Event()  # Event to signal stop of acquisition\n",
    "\n",
    "    def create_widgets(self):\n",
    "        # Frame for camera settings\n",
    "        settings_frame = ttk.LabelFrame(self.root, text=\"Camera Settings\")\n",
    "        settings_frame.grid(row=0, column=0, padx=10, pady=10, sticky=tk.W)\n",
    "\n",
    "        # FPS Entry\n",
    "        ttk.Label(settings_frame, text=\"FPS:\").grid(row=0, column=0, sticky=tk.W)\n",
    "        fps_entry = ttk.Entry(settings_frame, textvariable=self.fps)\n",
    "        fps_entry.grid(row=0, column=1, padx=5, pady=5)\n",
    "\n",
    "        # Exposure Entry\n",
    "        ttk.Label(settings_frame, text=\"Exposure (us):\").grid(row=1, column=0, sticky=tk.W)\n",
    "        exposure_entry = ttk.Entry(settings_frame, textvariable=self.exposure)\n",
    "        exposure_entry.grid(row=1, column=1, padx=5, pady=5)\n",
    "\n",
    "        # Output Filename Entry\n",
    "        ttk.Label(settings_frame, text=\"Output Filename:\").grid(row=2, column=0, sticky=tk.W)\n",
    "        output_entry = ttk.Entry(settings_frame, textvariable=self.output_filename)\n",
    "        output_entry.grid(row=2, column=1, padx=5, pady=5)\n",
    "\n",
    "        # Start Button\n",
    "        start_button = ttk.Button(self.root, text=\"Start Acquisition\", command=self.start_acquisition)\n",
    "        start_button.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "        # Stop Button\n",
    "        stop_button = ttk.Button(self.root, text=\"Stop Acquisition\", command=self.stop_acquisition_process)\n",
    "        stop_button.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "    def browse_output_file(self):\n",
    "        filename = filedialog.asksaveasfilename(defaultextension=\".avi\", filetypes=[(\"AVI files\", \"*.avi\")])\n",
    "        if filename:\n",
    "            self.output_filename.set(filename)\n",
    "\n",
    "    def configure_camera(self, cam):\n",
    "        nodemap = cam.GetNodeMap()\n",
    "        \n",
    "        # Set acquisition mode to continuous\n",
    "        node_acquisition_mode = PySpin.CEnumerationPtr(nodemap.GetNode('AcquisitionMode'))\n",
    "        node_acquisition_mode_continuous = node_acquisition_mode.GetEntryByName('Continuous')\n",
    "        node_acquisition_mode.SetIntValue(node_acquisition_mode_continuous.GetValue())\n",
    "        \n",
    "        # Set pixel format to Mono8 (8-bit grayscale)\n",
    "        node_pixel_format = PySpin.CEnumerationPtr(nodemap.GetNode('PixelFormat'))\n",
    "        node_pixel_format_mono8 = node_pixel_format.GetEntryByName('Mono8')\n",
    "        node_pixel_format.SetIntValue(node_pixel_format_mono8.GetValue())\n",
    "        \n",
    "        # Set maximum width\n",
    "        node_width = PySpin.CIntegerPtr(nodemap.GetNode('Width'))\n",
    "        max_width = node_width.GetMax()\n",
    "        node_width.SetValue(max_width)\n",
    "        \n",
    "        # Set maximum height\n",
    "        node_height = PySpin.CIntegerPtr(nodemap.GetNode('Height'))\n",
    "        max_height = node_height.GetMax()\n",
    "        node_height.SetValue(max_height)\n",
    "        \n",
    "        # Enable frame rate control\n",
    "        node_acquisition_frame_rate_enable = PySpin.CBooleanPtr(nodemap.GetNode('AcquisitionFrameRateEnable'))\n",
    "        node_acquisition_frame_rate_enable.SetValue(True)\n",
    "\n",
    "        # Set frame rate\n",
    "        node_frame_rate = PySpin.CFloatPtr(nodemap.GetNode('AcquisitionFrameRate'))\n",
    "        node_frame_rate.SetValue(self.fps.get())\n",
    "        \n",
    "        # Turn off auto exposure\n",
    "        node_exposure_auto = PySpin.CEnumerationPtr(nodemap.GetNode('ExposureAuto'))\n",
    "        node_exposure_auto_off = node_exposure_auto.GetEntryByName('Off')\n",
    "        node_exposure_auto.SetIntValue(node_exposure_auto_off.GetValue())\n",
    "        \n",
    "        # Turn off auto gain\n",
    "        node_gain_auto = PySpin.CEnumerationPtr(nodemap.GetNode('GainAuto'))\n",
    "        node_gain_auto_off = node_gain_auto.GetEntryByName('Off')\n",
    "        node_gain_auto.SetIntValue(node_gain_auto_off.GetValue())\n",
    "        \n",
    "        # Set exposure time (in microseconds)\n",
    "        node_exposure_time = PySpin.CFloatPtr(nodemap.GetNode('ExposureTime'))\n",
    "        node_exposure_time.SetValue(self.exposure.get())\n",
    "        \n",
    "        # Set gain (if needed)\n",
    "        node_gain = PySpin.CFloatPtr(nodemap.GetNode('Gain'))\n",
    "        node_gain.SetValue(10.0)  # Example: set gain to 10 dB\n",
    "\n",
    "    def acquire_video(self, cam):\n",
    "        # Create a VideoWriter object\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "        frame_width = int(cam.Width())\n",
    "        frame_height = int(cam.Height())\n",
    "        self.out = cv2.VideoWriter(f'{self.output_filename.get()}.avi', fourcc, self.fps.get(), (frame_width, frame_height), isColor=False)\n",
    "\n",
    "        try:\n",
    "            # Start the acquisition\n",
    "            cam.BeginAcquisition()\n",
    "\n",
    "            while not self.stop_acquisition.is_set():\n",
    "                # Retrieve next image\n",
    "                image_result = cam.GetNextImage()\n",
    "\n",
    "                if image_result.IsIncomplete():\n",
    "                    print('Image incomplete: ', image_result.GetImageStatus())\n",
    "                else:\n",
    "                    # Convert image to numpy array (Grayscale)\n",
    "                    frame = image_result.GetNDArray()\n",
    "\n",
    "                    # Process frame for ArUco detection\n",
    "                    self.detect_aruco(frame)\n",
    "\n",
    "                # Release image\n",
    "                image_result.Release()\n",
    "\n",
    "                # Check for 'Esc' key press to exit (optional)\n",
    "                if cv2.waitKey(1) == 27:  # Esc key\n",
    "                    break\n",
    "\n",
    "        finally:\n",
    "            # End acquisition\n",
    "            cam.EndAcquisition()\n",
    "\n",
    "            # Release VideoWriter and destroy OpenCV window\n",
    "            self.out.release()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "    def rotation_matrix_to_euler_angles(R):\n",
    "        \"\"\"Convert a rotation matrix to Euler angles (roll, pitch, yaw)\"\"\"\n",
    "        sy = math.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])\n",
    "        singular = sy < 1e-6\n",
    "        if not singular:\n",
    "            x = math.atan2(R[2, 1], R[2, 2])\n",
    "            y = math.atan2(-R[2, 0], sy)\n",
    "            z = math.atan2(R[1, 0], R[0, 0])\n",
    "        else:\n",
    "            x = math.atan2(-R[1, 2], R[1, 1])\n",
    "            y = math.atan2(-R[2, 0], sy)\n",
    "            z = 0\n",
    "        return np.degrees(np.array([x, y, z]))  # Convert to degrees\n",
    "\n",
    "    def detect_aruco(self, frame):\n",
    "        # f_x = (focal_length_mm * image_width) / sensor_width_mm\n",
    "        f_x = (13.5*1280)/6.14  # Focal length in pixels (x-axis) \n",
    "        f_y = (13.5*1024)/4.92 # Focal length in pixels (y-axis)\n",
    "\n",
    "        # Define camera parameters (these should be obtained from camera calibration)\n",
    "        camera_matrix = np.array([[f_x, 0, frame.shape[1] / 2],\n",
    "                                [0, f_y, frame.shape[0] / 2],\n",
    "                                [0, 0, 1]], dtype=np.float32)  # Example values, adjust accordingly\n",
    "        dist_coeffs = np.zeros((5, 1))  # Assuming no lens distortion\n",
    "\n",
    "        # Detect ArUco markers\n",
    "        corners, ids, _ = cv2.aruco.detectMarkers(frame, self.detector)\n",
    "\n",
    "        if ids is not None and len(ids) > 0:\n",
    "            # Draw detected markers on the frame\n",
    "            frame = cv2.aruco.drawDetectedMarkers(frame, corners, ids, borderColor=(255, 255, 255))\n",
    "\n",
    "            # Estimate pose of each marker to get tvecs (translation vectors)\n",
    "            marker_length = 0.05  # Example marker length in meters, adjust accordingly\n",
    "            rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, marker_length, camera_matrix, dist_coeffs)\n",
    "\n",
    "            for i in range(len(ids)):\n",
    "                # Get translation vector (position)\n",
    "                x, y, z = tvecs[i][0]\n",
    "                position_text = f\"Pos: ({x:.2f}, {y:.2f}, {z:.2f}) meters\"\n",
    "                cv2.putText(frame, position_text, (10, 30 + i * 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "\n",
    "                # Get rotation matrix from rotation vector\n",
    "                R, _ = cv2.Rodrigues(rvecs[i])\n",
    "\n",
    "                # Convert rotation matrix to Euler angles\n",
    "                roll, pitch, yaw = rotation_matrix_to_euler_angles(R)\n",
    "                rotation_text = f\"Rot: ({roll:.2f}, {pitch:.2f}, {yaw:.2f}) deg\"\n",
    "                cv2.putText(frame, rotation_text, (10, 60 + i*30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"ArUco Detection\", frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == 27:  # ESC key to exit\n",
    "            self.stop_acquisition_process()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    def start_acquisition(self):\n",
    "        # Start acquisition in a separate thread\n",
    "        self.stop_acquisition.clear()  # Clear the stop event flag\n",
    "        acquisition_thread = threading.Thread(target=self.run_acquisition)\n",
    "        acquisition_thread.start()\n",
    "\n",
    "    def run_acquisition(self):\n",
    "        system = PySpin.System.GetInstance()\n",
    "        cam_list = system.GetCameras()\n",
    "\n",
    "        try:\n",
    "            if cam_list.GetSize() == 0:\n",
    "                raise ValueError(\"No cameras found!\")\n",
    "\n",
    "            # Assume one camera for simplicity\n",
    "            cam = cam_list.GetByIndex(0)\n",
    "\n",
    "            # Initialize camera\n",
    "            cam.Init()\n",
    "\n",
    "            # Configure camera settings\n",
    "            self.configure_camera(cam)\n",
    "\n",
    "            # Acquire video until stop event is set\n",
    "            self.acquire_video(cam)\n",
    "\n",
    "            # Deinitialize camera\n",
    "            cam.DeInit()\n",
    "\n",
    "        except PySpin.SpinnakerException as ex:\n",
    "            print('Error: %s' % ex)\n",
    "            exit_code = 1\n",
    "\n",
    "        finally:\n",
    "            # Release camera and system resources\n",
    "            del cam\n",
    "            cam_list.Clear()\n",
    "            system.ReleaseInstance()\n",
    "\n",
    "    def stop_acquisition_process(self):\n",
    "        # Set the stop event flag to stop acquisition\n",
    "        self.stop_acquisition.set()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    root = tk.Tk()\n",
    "    app = CameraApp(root)\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import threading\n",
    "\n",
    "# Load the ArUco dictionary and parameters\n",
    "aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)\n",
    "parameters = cv2.aruco.DetectorParameters()\n",
    "\n",
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define camera matrix and distortion coefficients (dummy values for demonstration)\n",
    "# These values should ideally be obtained from camera calibration\n",
    "camera_matrix = np.array([[1000, 0, 320],\n",
    "                          [0, 1000, 240],\n",
    "                          [0, 0, 1]], dtype=np.float32)\n",
    "distortion_coefficients = np.zeros((5, 1), dtype=np.float32)\n",
    "\n",
    "def rotation_matrix_to_euler_angles(R):\n",
    "    \"\"\"Convert a rotation matrix to Euler angles (roll, pitch, yaw)\"\"\"\n",
    "    sy = math.sqrt(R[0, 0] * R[0, 0] + R[1, 0] * R[1, 0])\n",
    "    singular = sy < 1e-6\n",
    "    if not singular:\n",
    "        x = math.atan2(R[2, 1], R[2, 2])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = math.atan2(R[1, 0], R[0, 0])\n",
    "    else:\n",
    "        x = math.atan2(-R[1, 2], R[1, 1])\n",
    "        y = math.atan2(-R[2, 0], sy)\n",
    "        z = 0\n",
    "    return np.degrees(np.array([x, y, z]))  # Convert to degrees\n",
    "\n",
    "def capture_and_process():\n",
    "    global latest_frame\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Detect ArUco markers in the image\n",
    "        corners, ids, rejected_img_points = cv2.aruco.detectMarkers(gray, aruco_dict, parameters=parameters)\n",
    "\n",
    "        # If markers are detected\n",
    "        if len(corners) > 0:\n",
    "            # Draw detected markers (without axes)\n",
    "            frame = cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "            # Estimate pose of the markers\n",
    "            rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, 0.05, camera_matrix, distortion_coefficients)\n",
    "\n",
    "            # Loop over each detected marker\n",
    "            for i in range(len(ids)):\n",
    "                # Get translation vector (position)\n",
    "                x, y, z = tvecs[i][0]\n",
    "                position_text = f\"Pos: ({x:.2f}, {y:.2f}, {z:.2f}) meters\"\n",
    "                cv2.putText(frame, position_text, (10, 30 + i*30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "\n",
    "                # Get rotation matrix from rotation vector\n",
    "                R, _ = cv2.Rodrigues(rvecs[i])\n",
    "\n",
    "                # Convert rotation matrix to Euler angles\n",
    "                roll, pitch, yaw = rotation_matrix_to_euler_angles(R)\n",
    "                rotation_text = f\"Rot: ({roll:.2f}, {pitch:.2f}, {yaw:.2f}) deg\"\n",
    "                cv2.putText(frame, rotation_text, (10, 60 + i*30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "\n",
    "        # Store the latest frame for display\n",
    "        latest_frame = frame\n",
    "\n",
    "def display_frame():\n",
    "    while True:\n",
    "        if latest_frame is not None:\n",
    "            # Display the latest frame with overlaid text\n",
    "            cv2.imshow('Frame', latest_frame)\n",
    "\n",
    "        # Exit loop when 'Esc' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    # Release the capture and close the window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Shared variable for the latest frame\n",
    "latest_frame = None\n",
    "\n",
    "# Create and start threads\n",
    "capture_thread = threading.Thread(target=capture_and_process)\n",
    "display_thread = threading.Thread(target=display_frame)\n",
    "\n",
    "capture_thread.start()\n",
    "display_thread.start()\n",
    "\n",
    "# Wait for threads to finish\n",
    "capture_thread.join()\n",
    "display_thread.join()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointgrey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
